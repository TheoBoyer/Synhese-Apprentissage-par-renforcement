{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reinforcment_learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheoBoyer/Synhese-Apprentissage-par-renforcement/blob/master/Reinforcment_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHCNk2NcOkEN",
        "colab_type": "code",
        "outputId": "56b5158c-ec3b-42e9-ac6d-79024772c5ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Imports\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "2.1.0-rc1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRr4VqhxEn1U",
        "colab_type": "text"
      },
      "source": [
        "# Apprentissage par renforcement\n",
        "Ce notebook me permet de synthétiser tout ce que je trouverai sur l'apprentissage par renforcement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbT94tRmFUkR",
        "colab_type": "text"
      },
      "source": [
        "## Environnement\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9boiD5jZLi-E",
        "colab_type": "text"
      },
      "source": [
        "### Notions importantes\n",
        "**Définitions**:<br/>\n",
        "\n",
        "*   Un *environnement* est l'espace dans lequel les *Agents* évoluent.\n",
        "*   Un *environnement* possède différents *états*\n",
        "*   Un *état* est connecté aux autres *états* par des *actions*\n",
        "*   Une *récompense* est une valeure renvoyée par l'*environnement* pour dire si l'agent effectue des actions souhaitables ou non.\n",
        "\n",
        "**Exemple**:<br/>\n",
        "Si on souhaite créer un bot au puissance4:\n",
        "\n",
        "*   l'*environnement* $E$ correspond aux règles du jeu du puissance4\n",
        "*   Les *états* $e$ correspondront aux différentes configurations possibles de la grille de jeu.\n",
        "*   Les *actions* $a$ correspondront au fait de mettre une pièce dans une certaine colonne\n",
        "*   Les *récompenses* $r$ correspondront a une valeur de $+1$ si l'agent a gagné la partie, $-1$ si il l'a perdu et $0$ si la partie est en cours.\n",
        "\n",
        "**Caractérisation mathématique**:<br/>\n",
        "D'un point de vue mathématique, un environnement est vu comme une fonction qui admet un couple etat-acion et qui renvoie un couple etat-récompense:\n",
        "$$\n",
        "\\begin{align*}\n",
        "E(e, a) = (e', r)\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "**Implémentation**:<br/>\n",
        "Au vu de la caractérisation mathématique, on aurait envie d'implémenter un *environnement* avec une simple fonction. Cela pourrait fonctionner mais en pratique, on préferera créer une classe, pour pouvoir utiliser des attributs propres à l'*environnement* et qui ne figureront pas dans les *états*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGP4CW_NLUwl",
        "colab_type": "text"
      },
      "source": [
        "### Environnement aléatoire\n",
        "Cet environnement est un simple environnement déterministe, mais aléatoire, pour pouvoir faire des tests en aveugle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLA3Y2HpEjHb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EnvAleatoire:\n",
        "  def __init__(self, largeur, profondeur, taille_etat, n_var_latentes, graine):\n",
        "    np.random.seed(graine)\n",
        "    self.largeur = largeur\n",
        "    self.profondeur = profondeur\n",
        "    self.var_latentes = np.random.random(n_var_latentes)\n",
        "    self.\n",
        "  \n",
        "  def env(self, etat, action):\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}